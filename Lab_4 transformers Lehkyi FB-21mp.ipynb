{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "075d1621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3ad57bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████| 629/629 [00:00<?, ?B/s]\n",
      "C:\\Users\\GreenLHK\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:127: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\GreenLHK\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 268M/268M [00:22<00:00, 11.8MB/s]\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████| 48.0/48.0 [00:00<?, ?B/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 494kB/s]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ff9a0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9897316098213196}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_1 = 'I worry about weather.'\n",
    "classifier(txt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78b51c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9962466359138489}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_2 = 'I am a little worried about the weather.'\n",
    "classifier(txt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "858a0df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.8732656240463257}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_4 = 'The car is parked close to the house.'\n",
    "classifier(txt_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6731d6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9963782429695129}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_5 = 'Bill sometimes has bad mood, sometimes good.'\n",
    "classifier(txt_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af2f8e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9666711688041687}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_6 = 'The car was going somewhere'\n",
    "classifier(txt_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b91ad079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.695081889629364}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_3 = 'The weather is unpredictable around here'\n",
    "classifier(txt_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de192a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████| 570/570 [00:00<?, ?B/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 536M/536M [00:45<00:00, 11.8MB/s]\n",
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████| 28.0/28.0 [00:00<?, ?B/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 704kB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 764kB/s]\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d9edb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.6867286562919617,\n",
       "  'token': 2204,\n",
       "  'token_str': 'good',\n",
       "  'sequence': \"hello i'm a fashion model. good to see you\"},\n",
       " {'score': 0.2059156596660614,\n",
       "  'token': 3835,\n",
       "  'token_str': 'nice',\n",
       "  'sequence': \"hello i'm a fashion model. nice to see you\"},\n",
       " {'score': 0.05429702252149582,\n",
       "  'token': 2307,\n",
       "  'token_str': 'great',\n",
       "  'sequence': \"hello i'm a fashion model. great to see you\"},\n",
       " {'score': 0.011749433353543282,\n",
       "  'token': 6919,\n",
       "  'token_str': 'wonderful',\n",
       "  'sequence': \"hello i'm a fashion model. wonderful to see you\"},\n",
       " {'score': 0.007843973115086555,\n",
       "  'token': 5580,\n",
       "  'token_str': 'glad',\n",
       "  'sequence': \"hello i'm a fashion model. glad to see you\"}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Hello I'm a fashion model. [MASK] to see you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5b2c36e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.039320677518844604,\n",
       "  'token': 2184,\n",
       "  'token_str': '10',\n",
       "  'sequence': 'i get 10 points on test.'},\n",
       " {'score': 0.034337930381298065,\n",
       "  'token': 2093,\n",
       "  'token_str': 'three',\n",
       "  'sequence': 'i get three points on test.'},\n",
       " {'score': 0.03251273185014725,\n",
       "  'token': 2274,\n",
       "  'token_str': 'five',\n",
       "  'sequence': 'i get five points on test.'},\n",
       " {'score': 0.031305648386478424,\n",
       "  'token': 2053,\n",
       "  'token_str': 'no',\n",
       "  'sequence': 'i get no points on test.'},\n",
       " {'score': 0.028820592910051346,\n",
       "  'token': 2416,\n",
       "  'token_str': 'six',\n",
       "  'sequence': 'i get six points on test.'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"I get [MASK] points on test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bdacd5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.23865929245948792,\n",
       "  'token': 4933,\n",
       "  'token_str': 'stuff',\n",
       "  'sequence': 'i bought really good stuff and enjoyed it all day long.'},\n",
       " {'score': 0.1457095742225647,\n",
       "  'token': 2833,\n",
       "  'token_str': 'food',\n",
       "  'sequence': 'i bought really good food and enjoyed it all day long.'},\n",
       " {'score': 0.08783051371574402,\n",
       "  'token': 9485,\n",
       "  'token_str': 'candy',\n",
       "  'sequence': 'i bought really good candy and enjoyed it all day long.'},\n",
       " {'score': 0.054121386259794235,\n",
       "  'token': 10733,\n",
       "  'token_str': 'pizza',\n",
       "  'sequence': 'i bought really good pizza and enjoyed it all day long.'},\n",
       " {'score': 0.03617053106427193,\n",
       "  'token': 4253,\n",
       "  'token_str': 'clothes',\n",
       "  'sequence': 'i bought really good clothes and enjoyed it all day long.'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"I bought really good [MASK] and enjoyed it all day long.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dcaabcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████| 665/665 [00:00<?, ?B/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 498M/498M [00:42<00:00, 11.8MB/s]\n",
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████| 1.04M/1.04M [00:00<00:00, 1.39MB/s]\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 803kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████| 1.36M/1.36M [00:00<00:00, 1.76MB/s]\n"
     ]
    }
   ],
   "source": [
    "generator_GPT2 = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b32bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    " set_seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8118628a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, I'm a language model, I don't think I really understand anything new. So I think I can still use this library as a front\"},\n",
       " {'generated_text': 'Hello, I\\'m a language model, that\\'s something I\\'ve wanted to do for a long time,\" Travin said when asked if he felt'},\n",
       " {'generated_text': \"Hello, I'm a language model, I wrote my first code (in a Scala IDE and compiled code) and finally my first class library, which\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not a language model. I never thought I'd find myself in an amazing place without it. Now I do\"},\n",
       " {'generated_text': \"Hello, I'm a language model, not just a programming model. I'm just one of the many. These models are the model that sets me\"}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_GPT2(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "04712f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Sherlock Holmes drove his car to the scene. The incident involved a Ford Impala, one of the suspects was the passenger, and he was pulled over for driving while having a history of petty theft.\\n\\nPolice determined the'},\n",
       " {'generated_text': \"Sherlock Holmes drove his car to a different location in L.A., but there he got some weird results. The car he'd lost had only one body and the seat he'd clipped was one of them. And he had\"},\n",
       " {'generated_text': \"Sherlock Holmes drove his car to a family estate after spending the day at a spa in Los Angeles but couldn't get inside to spend time with his wife or daughter because he wasn't allowed inside.\\n\\nHolmes, 59\"},\n",
       " {'generated_text': 'Sherlock Holmes drove his car to the corner of Fifth Avenue and LaFerrari with an apparent intention of killing himself. Detective John Stowell was the first person to catch up with this case, and he immediately took off his'},\n",
       " {'generated_text': 'Sherlock Holmes drove his car to work in the parking lot and found a woman who worked at its gas station. Sherlock said that his mother was in her sleep and tried to explain her daughter went to work a few hours early this'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_GPT2(\"Sherlock Holmes drove his car to\", max_length=46, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92d0a22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The story about summer holidays started with this post from a reader. She wanted to share her experiences of staying this long in Minnesota or trying more days and nights at home. Below are some of the most interesting articles about staying late in Minnesota.\\n\\nLazy Week\\n\\nOne'},\n",
       " {'generated_text': \"The story about summer holidays started with the story about summer holiday. You need that and more than that to stay motivated and motivated. That's what's motivating you to come back here and join the team.\\n\\nWe've been looking to recruit good staff and we want a dedicated\"},\n",
       " {'generated_text': 'The story about summer holidays started with the kids and what parents would do,\" a parent. \"They would say they\\'d have a lot of chocolate on the weekends and they\\'d go play at their friends\\' houses. We had kids at school and in the family, but they were'},\n",
       " {'generated_text': 'The story about summer holidays started with the rise of social media. You can see it here. You can read this great article by Alex Lifschitz about it here: http://www.dailymail.co.uk/news/article-11594627/Why-'},\n",
       " {'generated_text': 'The story about summer holidays started with me having fun in my closet. It has become such a large part of my life that it has been hard to separate the different holidays that we used to have at home. For some reason, when I was doing some shopping in my basement,'},\n",
       " {'generated_text': 'The story about summer holidays started with a story about a black couple from Brooklyn. A little-known black comedian who spent the past three years going to South Africa was born in New York City. Now he\\'s got a New York-based TV show called \"Howlheads.\"'},\n",
       " {'generated_text': 'The story about summer holidays started with some simple questions like, \"How did we get here?\" and \"How long did I have to travel?\" and then more on our journey. We didn\\'t find out until later on, just when our family was in Canada and we weren\\'t'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_GPT2(\"The story about summer holidays started with\", max_length=56, num_return_sequences=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f4919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
